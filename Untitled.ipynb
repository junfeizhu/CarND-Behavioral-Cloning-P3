{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda, Activation\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers import Cropping2D\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = []\n",
    "with open('C:/Users/jeffz/Desktop/data/driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        samples.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples, validation_samples = train_test_split(samples, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(samples, batch_size=32):\n",
    "    num_samples = len(samples)\n",
    "    while 1:\n",
    "        sklearn.utils.shuffle(samples)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "            \n",
    "            images = []\n",
    "            angles = []\n",
    "            for batch_sample in batch_samples:\n",
    "                center_image = cv2.imread(batch_sample[0]) \n",
    "                center_angle = float(batch_sample[3])\n",
    "                images.append(center_image)\n",
    "                angles.append(center_angle)\n",
    "             \n",
    "            augmented_images, augmented_angles = [], []\n",
    "            for image, angle in zip(images, angles):\n",
    "                augmented_images.append(image)\n",
    "                augmented_angles.append(angle)\n",
    "                augmented_images.append(cv2.flip(image,1))\n",
    "                augmented_angles.append(angle*-1.0)\n",
    "            \n",
    "            X_train = np.array(augmented_images)\n",
    "            y_train = np.array(augmented_angles)\n",
    "            yield sklearn.utils.shuffle(X_train, y_train)\n",
    "            \n",
    "            \n",
    "train_generator = generator(train_samples, batch_size=32)\n",
    "validation_generator = generator(validation_samples, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "with open('C:/Users/jeffz/Desktop/data/driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:        \n",
    "        lines.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "del lines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "measurements = []\n",
    "for line in lines:\n",
    "    current_path = line[0]\n",
    "    image = cv2.imread(current_path)\n",
    "    images.append(image)\n",
    "    measurement = float(line[3])\n",
    "    measurements.append(measurement)\n",
    "\n",
    "augmented_images, augmented_measurements = [], []\n",
    "for image, measurement in zip(images, measurements):\n",
    "    augmented_images.append(image)\n",
    "    augmented_measurements.append(measurement)\n",
    "    augmented_images.append(cv2.flip(image,1))\n",
    "    augmented_measurements.append(measurement*-1.0)\n",
    "    \n",
    "    \n",
    "X_train = np.array(augmented_images)\n",
    "y_train = np.array(augmented_measurements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21128, 160, 320, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "8448/8452 [============================>.] - ETA: 0s - loss: 0.0103"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeffz\\Anaconda3\\envs\\carnd-term1-gpu\\lib\\site-packages\\keras\\engine\\training.py:1569: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.\n",
      "  warnings.warn('Epoch comprised more than '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8512/8452 [==============================] - 22s - loss: 0.0102 - val_loss: 0.0080\n",
      "Epoch 2/3\n",
      "8456/8452 [==============================] - 16s - loss: 0.0076 - val_loss: 0.0075\n",
      "Epoch 3/3\n",
      "8512/8452 [==============================] - 16s - loss: 0.0079 - val_loss: 0.0072\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Lambda(lambda x:(x/255.0)-0.5, input_shape=(160,320,3)))\n",
    "model.add(Cropping2D(cropping=((50,20),(0,0))))\n",
    "\n",
    "model.add(Convolution2D(24,5,5))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(36,5,5))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(48,5,5))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Activation('relu'))\n",
    "          \n",
    "model.add(Convolution2D(64,3,3))\n",
    "model.add(Activation('relu'))  \n",
    "          \n",
    "model.add(Convolution2D(64,3,3))\n",
    "model.add(Activation('relu'))  \n",
    "          \n",
    "model.add(Flatten())\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "          \n",
    "model.add(Dense(50))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "#model.fit(X_train, y_train, validation_split=0.2, shuffle=True, nb_epoch=3)\n",
    "model.fit_generator(train_generator, samples_per_epoch=len(train_samples)*2, validation_data=validation_generator, nb_val_samples=len(validation_samples), nb_epoch=3)\n",
    "\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jeffz\\Anaconda3\\envs\\carnd-term1-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1023: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\Users\\jeffz\\Anaconda3\\envs\\carnd-term1-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1084: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "Train on 16902 samples, validate on 4226 samples\n",
      "Epoch 1/3\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Lambda(lambda x:(x/255.0)-0.5, input_shape=(160,320,3)))\n",
    "model.add(Cropping2D(cropping=((50,20),(0,0))))\n",
    "model.add(Convolution2D(24,5,5,subsample=(2,2),activation=\"relu\"))\n",
    "model.add(Convolution2D(36,5,5,subsample=(2,2),activation=\"relu\"))\n",
    "model.add(Convolution2D(48,5,5,subsample=(2,2),activation=\"relu\"))\n",
    "model.add(Convolution2D(64,3,3,activation=\"relu\"))\n",
    "model.add(Convolution2D(64,3,3,activation=\"relu\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(50))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.fit(X_train, y_train, validation_split=0.2, shuffle=True, nb_epoch=3)\n",
    "\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
