{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda, Activation,Dropout\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers import Cropping2D\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = []\n",
    "with open('D:/learning/udacity/CarND/term1/data/P3_data/data/driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        samples.append(line)\n",
    "\n",
    "del samples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples, validation_samples = train_test_split(samples, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(samples, batch_size=32):\n",
    "    num_samples = len(samples)\n",
    "    while 1:\n",
    "        sklearn.utils.shuffle(samples)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "            \n",
    "            images = []\n",
    "            angles = []\n",
    "            for batch_sample in batch_samples:\n",
    "                source_path = batch_sample[0]\n",
    "                filename = source_path.split('/')[-1]\n",
    "                center_current_path ='D:/learning/udacity/CarND/term1/data/P3_data/data/IMG/'+filename\n",
    "                \n",
    "                source_path = batch_sample[1]\n",
    "                filename = source_path.split('/')[-1]\n",
    "                left_current_path ='D:/learning/udacity/CarND/term1/data/P3_data/data/IMG/'+filename\n",
    "                \n",
    "                source_path = batch_sample[2]\n",
    "                filename = source_path.split('/')[-1]\n",
    "                right_current_path ='D:/learning/udacity/CarND/term1/data/P3_data/data/IMG/'+filename\n",
    "                \n",
    "                center_image = cv2.imread(center_current_path) \n",
    "                center_angle = float(batch_sample[3])\n",
    "                center_image = cv2.cvtColor(center_image,cv2.COLOR_BGR2RGB)\n",
    "                \n",
    "                left_image = cv2.imread(left_current_path)\n",
    "                left_angle = float(batch_sample[3])+0.2\n",
    "                left_image = cv2.cvtColor(left_image,cv2.COLOR_BGR2RGB)\n",
    "                \n",
    "                \n",
    "                right_image = cv2.imread(right_current_path)\n",
    "                right_angle = float(batch_sample[3])-0.2\n",
    "                right_image = cv2.cvtColor(right_image,cv2.COLOR_BGR2RGB)\n",
    "                \n",
    "                images.append(center_image)\n",
    "                angles.append(center_angle)\n",
    "                \n",
    "                images.append(left_image)\n",
    "                angles.append(left_angle)\n",
    "                \n",
    "                images.append(right_image)\n",
    "                angles.append(right_angle)\n",
    "             \n",
    "            augmented_images, augmented_angles = [], []\n",
    "            for image, angle in zip(images, angles):\n",
    "                augmented_images.append(image)\n",
    "                augmented_angles.append(angle)\n",
    "                augmented_images.append(cv2.flip(image,1))\n",
    "                augmented_angles.append(angle*-1.0)\n",
    "            \n",
    "            X_train = np.array(augmented_images)\n",
    "            y_train = np.array(augmented_angles)\n",
    "            yield sklearn.utils.shuffle(X_train, y_train)\n",
    "            \n",
    "            \n",
    "train_generator = generator(train_samples, batch_size=32)\n",
    "validation_generator = generator(validation_samples, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jeffz\\Anaconda3\\envs\\carnd-term1-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1023: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\Users\\jeffz\\Anaconda3\\envs\\carnd-term1-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1084: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "Epoch 1/3\n",
      "38568/38568 [==============================] - 51s - loss: 0.0197 - val_loss: 0.0140\n",
      "Epoch 2/3\n",
      "38568/38568 [==============================] - 37s - loss: 0.0160 - val_loss: 0.0159\n",
      "Epoch 3/3\n",
      "38568/38568 [==============================] - 37s - loss: 0.0143 - val_loss: 0.0130\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Lambda(lambda x:(x/255.0)-0.5, input_shape=(160,320,3)))\n",
    "model.add(Cropping2D(cropping=((60,20),(0,0))))\n",
    "model.add(Convolution2D(24,5,5,subsample=(2,2),activation=\"relu\"))\n",
    "#model.add(Dropout(0.8))\n",
    "model.add(Convolution2D(36,5,5,subsample=(2,2),activation=\"relu\"))\n",
    "#model.add(Dropout(0.8))\n",
    "model.add(Convolution2D(48,5,5,subsample=(2,2),activation=\"relu\"))\n",
    "#model.add(Dropout(0.8))\n",
    "model.add(Convolution2D(64,3,3,activation=\"relu\"))\n",
    "#model.add(Dropout(0.8))\n",
    "model.add(Convolution2D(64,3,3,activation=\"relu\"))\n",
    "#model.add(Dropout(0.8))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100))\n",
    "#model.add(Dropout(0.8))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(50))\n",
    "#model.add(Dropout(0.8))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10))\n",
    "#model.add(Dropout(0.8))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.fit_generator(train_generator, samples_per_epoch=len(train_samples)*6, validation_data=validation_generator, nb_val_samples=len(validation_samples), nb_epoch=3)\n",
    "\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
